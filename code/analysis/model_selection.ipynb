{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2017 the authors. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "\n",
    "# Useful plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the plotting style.\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import mwc_mutants_utils as mwc\n",
    "mwc.set_plotting_style()\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline (only use with static plots (non-Bokeh))\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model selection between single parameter change and multiple parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore the use of Bayesian model selection to distinguish between changes in the parameters that a single point mutation in the transcription factor can cause. Specifically we will be comparing two models:\n",
    "1. $M_1$: A single family of parameters ($\\Delta\\varepsilon_{RA}$ for the DNA binding domain mutants and $K_A$ and $K_I$ for inducer binding pocket mutants) change when a single amino-acid substitution takes place on a specific part of the repressor.\n",
    "2. $M_2$: All mutations in the transcription factor change all parameters having to do with the protein (except for $\\Delta\\varepsilon_{AI}$), i.e. $\\Delta\\varepsilon_{RA}$, $K_A$, and $K_I$.\n",
    "\n",
    "The advantage of using Bayesian model selection is that intrinsically by the nature of the methodology 3 features are compared between models:\n",
    "1. Prior information on how likely is each of the models to be true.\n",
    "2. Goodness of fit of the model with the data.\n",
    "3. Complexity of the model.\n",
    "\n",
    "The framework then compares how well the model describes the data, but also how complicated is the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how these features are natually compared within the Bayesian framework we can write Bayes theorem for a model $M_i$ being true as\n",
    "$$\n",
    "P(M_i \\mid D) = \\frac{P(D \\mid M_i) P(M_i)}{P(D)},\n",
    "\\tag{1}\n",
    "$$\n",
    "where $D$ is the data. In principle the denominator can be computed as\n",
    "$$\n",
    "P(D) = \\sum_j P(D \\mid M_j)P(M_j),\n",
    "\\tag{2}\n",
    "$$\n",
    "where we would have to sum over all possible models, making it impossible to ever compute the probability of a specific model being true. But we can instead compare two models $M_1$ and $M_2$. Since the denominator would be the same for both we can write\n",
    "$$\n",
    "\\frac{P(M_1 \\mid D)}{P(M_2 \\mid D)} = \\frac{P(D \\mid M_1) P(M_i)}{P(D \\mid M_2) P(M_i)}.\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "For a given model $M_i$ with parameters $\\mathbf{a}_i$ we have that\n",
    "$$\n",
    "P(D \\mid M_i) = \\int d\\mathbf{a}_i P(D \\mid \\mathbf{a}_i, M_i) P(\\mathbf{a}_i \\mid M_i)\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "In general this integral is not easy to compute analitically and one has to use parallel temporing MCMC (to be discussed later) to perform this integral numerically. But for cases where the posterior distribution of the parameters is single peaked and more or less symmetric (i.e. Gaussian-like) one can approximate the integral with the area of a rectangle. This simplification is known as the Laplace approximation and it is written as\n",
    "$$\n",
    "P(D \\mid M_i) \\approx P(\\mathbf{a}_i^* \\mid M_i) \\underbrace{P(D \\mid \\mathbf{a}_i^*, M_i)}_\\text{height} \\underbrace{(2\\pi)^{\\vert \\mathbf{a}_i \\vert / 2} \\sqrt{\\det \\boldsymbol{\\sigma}_i^2}}_\\text{width},\n",
    "\\tag{5}\n",
    "$$\n",
    "where $\\mathbf{a}_i^*$ represents the most likely parameter values, $\\vert \\mathbf{a}_i \\vert$ represents the number of parameters in the model, and $\\boldsymbol{\\sigma}_i$ is the covariance matrix that can be computed with the Gaussian approximation of the parameter posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this approximation we can write the odds ratio, i.e. the probability ratio between two models as\n",
    "$$\n",
    "O_{ij} = \\underbrace{\\left[ \\frac{P(M_i)}{P(M_j)} \\right]}_\\text{prior on model}\n",
    "\\underbrace{\\left[ \\frac{P(D \\mid \\mathbf{a}_i^*, M_i)}{P(D \\mid \\mathbf{a}_j^*, M_j)} \\right]}_\\text{goodness of fit}\n",
    "\\underbrace{\\left[ \\frac{P(\\mathbf{a}_i^* \\mid M_i) (2\\pi)^{\\vert \\mathbf{a}_i^* \\vert / 2 } \\sqrt{\\det \\boldsymbol{\\sigma}_i^2}}{P(\\mathbf{a}_j^* \\mid M_j) (2\\pi)^{\\vert \\mathbf{a}_j^* \\vert / 2 } \\sqrt{\\det \\boldsymbol{\\sigma}_j^2}} \\right]}_\\text{Occam factor}.\n",
    "\\tag{6}\n",
    "$$\n",
    "\n",
    "This form of the odds ratio explicitly compares the 3 features mentioned above. For the Occam factor what it is accounting is the volume in parameter space in which the parameters can live. This naturally penalizes more complex models with many more parameters, giving a natural origin to [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual when dealing with probabilities is easier to take the log. For the case of the Odds ratio we have\n",
    "\\begin{align}\n",
    "\\log O_{ij} &= \\log \\left[ \\frac{P(M_i)}{P(M_j)} \\right]\\\\\n",
    "&+ \\log P(D \\mid \\mathbf{a}_i^*, M_i) - \\log P(D \\mid \\mathbf{a}_j^*, M_j)\\\\\n",
    "&+ \\log P(\\mathbf{a}_i^* \\mid M_i) - \\log P(\\mathbf{a}_j^* \\mid M_j)\\\\\n",
    "&+ \\frac{\\vert \\mathbf{a}_i^* \\vert  - \\vert \\mathbf{a}_j^* \\vert}{2} \\log 2\\pi\\\\\n",
    "&+ \\frac{1}{2}\\left( \\log \\boldsymbol{\\sigma}_i^2 - \\log \\boldsymbol{\\sigma}_j^2 \\right)\n",
    "\\tag{7}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA-binding domain mutants.\n",
    "\n",
    "Let's work out the specific case for DNA-binding domain mutants in which\n",
    "1. $M_1$ : only the $\\Delta\\varepsilon_{RA}$ is changed.\n",
    "2. $M_2$ : $\\Delta\\varepsilon_{RA}$ along with $K_A$ and $K_I$ are changed.\n",
    "\n",
    "We will assume that a priori both models are equally likely such that the first term of Eq. (7) is zero. We will also assume that each data point is independent of each other such that\n",
    "$$\n",
    "\\log P(D \\mid \\mathbf{a}_i^*, M_i) = \\sum_{d \\in D} \\log P(d \\mid \\mathbf{a}_i^*, M_i),\n",
    "\\tag{8}\n",
    "$$\n",
    "where $d$ is an individual data point of the dataset $D$.\n",
    "\n",
    "We will assign a Gaussian likelihood with constant error across IPTG concentrations such that\n",
    "\\begin{align}\n",
    "\\sum_{d \\in D} \\log P(d \\mid \\mathbf{a}_i^*, {\\sigma_i^*}, M_i) &= \n",
    "\\frac{n}{2} \\log \\left( 2 \\pi  {\\sigma_i^*}^2 \\right) \\\\\n",
    "&- \\sum_{d \\in D} \\frac{\\left( \\text{fold-change}_{exp} - \\text{fold-cange}_{thry}^{(d)}(\\mathbf{a}_i^*)\\right)^2}{2 {\\sigma_i^*}^2},\n",
    "\\tag{9}\n",
    "\\end{align}\n",
    "where $n = \\vert D \\vert$ is the number of data points, ${\\sigma_i^*}$ is the most likely error associated with the Gaussian likelihood, $\\text{fold-cange}_{exp}^{(d)}$ is the experimental fold change of the $d^{\\text{th}}$ data point and $\\text{fold-cange}_{thry}^{(d)}$ is the experimental prediction for the same datum.\n",
    "\n",
    "Finally for the prior on the parameters we will assume uniform priors for $\\Delta\\varepsilon_{RA}$, $\\tilde{k}_A \\equiv -\\log K_A / 1M$, and $\\tilde{k}_I \\equiv -\\log K_I / 1M$, and a Jeffreys' prior for the $\\sigma_i$ parameter associated with the Gaussian likelihood, obtaining\n",
    "$$\n",
    "\\log P(\\mathbf{a}_1^*, \\sigma_1 \\mid M_1) - \\log P(\\mathbf{a}_2^*, \\sigma_2 \\mid M_2) = \\left[ \\log P(\\Delta\\varepsilon_{RA} \\mid M_1)  + \\log P(\\sigma_1 \\mid M_1) \\right]\n",
    "- \\left[ \\log P(\\Delta\\varepsilon_{RA} \\mid M_2) + \\log P(\\tilde{k_A} \\mid M_2) + \\log P(\\tilde{k_I} \\mid M_2) + \\log P(\\sigma_2 \\mid M_2) \\right].\n",
    "\\tag{10}\n",
    "$$\n",
    "Since for both models $\\Delta\\varepsilon_{RA}$ and $\\sigma$ represent the same thing, the prior on these parameters should be the same so that those terms are canceled out. Since we stated that the parameters had a uniform prior we then can write this as\n",
    "$$\n",
    "\\log P(\\mathbf{a}_1^*, \\sigma_1 \\mid M_1) - \\log P(\\mathbf{a}_2^*, \\sigma_2 \\mid M_2) = \\left[ \\log \\left( \\tilde{k}_A^{\\max} - \\tilde{k}_A^{\\min} \\right) + \\log \\left( \\tilde{k}_I^{\\max} - \\tilde{k}_I^{\\min} \\right) \\right]\n",
    "\\tag{11}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all these terms together gives a log odds ratio\n",
    "\\begin{align}\n",
    "\\log O_{12} &= \\frac{n}{2} \\log \\left( 2 \\pi  {\\sigma_1^*}^2 \\right)\n",
    "- \\sum_{d \\in D} \\frac{\\left( \\text{fold-change}_{exp} - \\text{fold-cange}_{thry}^{(d)}({\\Delta\\varepsilon_{RA}}_1^*)\\right)^2}{2 {\\sigma_1^*}^2}\\\\\n",
    "&+ \\frac{n}{2} \\log \\left( 2 \\pi  {\\sigma_2^*}^2 \\right)\n",
    "- \\sum_{d \\in D} \\frac{\\left( \\text{fold-change}_{exp} - \\text{fold-cange}_{thry}^{(d)}({\\Delta\\varepsilon_{RA}}_2^*, {\\tilde{k}_A}_2^*, {\\tilde{k}_I}_2^*) \\right)^2}{2 {\\sigma_2^*}^2}\\\\\n",
    "&+ \\log \\left( \\tilde{k}_A^{\\max} - \\tilde{k}_A^{\\min} \\right) + \\log \\left( \\tilde{k}_I^{\\max} - \\tilde{k}_I^{\\min} \\right) \\\\\n",
    "&+ \\log 2\\pi \\\\\n",
    "&+ \\frac{1}{2} \\left( \\log \\det \\boldsymbol{\\sigma}_1^2 - \\log \\det \\boldsymbol{\\sigma}_2^2 \\right),\n",
    "\\tag{12}\n",
    "\\end{align}\n",
    "where $\\boldsymbol{\\sigma}_1^2$ is the covariance matrix for the two parameters for model $M_1$ ($\\Delta\\varepsilon_{RA}$ and $\\sigma_1$) and $\\boldsymbol{\\sigma}_2$ is the covariance matrix for the four parameters for model $M_2$ ($\\Delta\\varepsilon_{RA}$, $\\tilde{k}_A$, $\\tilde{k}_I$, and $\\sigma_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
